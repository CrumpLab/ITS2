---
title: "WW model"
author: "Matt Crump"
date: "11/18/2019"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 2
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```

```{r}
library(RsemanticLibrarian)
library(LSAfun)
library(ggplot2)
library(ggcorrplot)
library(ggpubr)
```

## Define some functions

```{r}
row_H <- function(x){
  if(sum(x-x[1])==0) return(1)
  return(-1*sum(x*log2(x), na.rm=TRUE))
}

matrix_H <- function(x){
  return(mean(apply(x,1,row_H)))
}

sim_I <- function(x){
  max_error <- dim(x)[1]*dim(x)[2]*4
  # all ones matrix
  same_error <- sum((x - matrix(1,ncol=dim(x)[2],nrow =dim(x)[2]))^2)
  # identity matrix
  diff_error <- sum((x - diag(dim(x)[1])^2))
  
  return(log(same_error/diff_error))
}


higher_order_sim <-  function(x,range=1:5, graph=FALSE){
  if(graph==TRUE){
    cor_plots <- list()
    sim_save <- list()
    cor_plots[[1]] <- ggcorrplot(x, show.legend = FALSE)
    sim_save[[1]] <- x
  }
  informativeness <- sim_I(x)
  for(i in range){
    if(i ==1){
      higher <- cosine(x)
      informativeness <- c(informativeness,sim_I(higher))
      if(graph==TRUE) {
        cor_plots[[1+i]] <- ggcorrplot(higher, show.legend = FALSE)
        higher[is.na(higher)]<-0
        sim_save[[1+i]] <- higher
      }
    }else{
      higher <- cosine(higher)
      informativeness <- c(informativeness,sim_I(higher))
      if(graph==TRUE) {
        higher[is.na(higher)]<-0
        sim_save[[1+i]] <- higher
        cor_plots[[1+i]] <- ggcorrplot(higher, show.legend = FALSE)
      }
    }
  }
  
  if(graph==TRUE) return(list(informativeness,plots=cor_plots, sims=sim_save))
  if(graph==FALSE) return(informativeness)
}

```

## define language

```{r}
frequency_matrix <- matrix(
  sample(1:100,100*1000,replace=TRUE),
  byrow=TRUE,
  ncol=1000,
  nrow=100
)

overlap <- matrix(0,ncol=1000,nrow=100)
for(i in 1:100){
  overlap[i,]<-sample(c(rep(1,100),rep(0,900)),1000)
}

high_freq_overlap <- sample(1:100,100)
for(i in 1:100){
  frequency_matrix[i,901:1000] <- high_freq_overlap
  overlap[i,901:1000] <- 1
}

frequency_matrix <- frequency_matrix*overlap
prob_matrix <- frequency_matrix/rowSums(frequency_matrix)
veridical_sims <- cosine(prob_matrix)

nth_similarity <- higher_order_sim(veridical_sims,1:3, graph=FALSE)

```

# sentence generator function

```{r}
# sentence generator function
generate_sentence <- function(num_to_make=100,
                              s_length_range= 4:10,
                              topics_to_sample = 1:10,
                              topic_prob = rep(.1,10),
                              prob_mat = prob_matrix){
  all_sentences <- list()
  for(i in 1:num_to_make){
    sample_topic <- sample(topics_to_sample,1, prob = topic_prob)
    sample_length <- sample(s_length_range)
    sample_sentence <- c(sample(1:dim(prob_mat)[2],sample_length,
                                replace=TRUE,
                                prob=prob_mat[sample_topic,]))
    all_sentences[[i]] <- sample_sentence
  }
  return(all_sentences)
}
```

## make corpus

```{r}
corpus <- generate_sentence(num_to_make=5000,
                             s_length_range= 10:20,
                             topics_to_sample = 1:100,
                             topic_prob = rep(.01,100),
                             prob_mat = prob_matrix)
```


```{r}
# turn corpus into windowed corpus
windowed_corpus <- function(num_sentences,corpus,window){
  a<-lapply(1:num_sentences,FUN =function(x){embed(corpus[[x]],window)[ ,window:1]})
  b<-do.call(rbind, a)
  return(b)
}

# WW function
window_co_occur2 <- function(x, WW_in = WW){
  for(i in 1:length(x)){
    t_x <- table(x[-i])
    nt_x <- as.numeric(names(t_x))
    WW_in[x[i],nt_x] <- WW_in[x[i],nt_x]+t_x
  }
  return(WW_in)
 }
 
# get WW matrices as a function of training 
get_WW_training <- function(corpus,
                            training_intervals = c(100,500,1000,5000),
                            n_words = 100,
                            ws = 3){
  WW_list<-list()
  lcnt<-0
  WW <- matrix(0, ncol=n_words, nrow=n_words)
  for(i in 1:max(training_intervals)){
    windowed_sentence <- windowed_corpus(1,corpus[i],ws)
    for(j in 1:dim(windowed_sentence)[1]){
      WW <- window_co_occur2(windowed_sentence[j,],WW)
    }
    if(i %in% training_intervals == TRUE){
      lcnt<-lcnt+1
      WW_list[[lcnt]] <- WW
    }
  }
  WW_list <- setNames(WW_list,training_intervals)
  return(WW_list)
}

# compute R squared
get_rsquared <- function(WW,nth,ws){
  all_df <- data.frame()
  for(i in 1:length(WW)){
    word_vec <- c(WW[[i]])
    word_vec[is.na(word_vec)] <- 0
    for(j in 1:length(nth$sims)){
      nth_vec <- c(nth$sims[j][[1]])
      nth_vec[is.na(nth_vec)] <- 0
      rsquare <- cor(word_vec,nth_vec)^2
      t_df <- data.frame(window=ws,
                         training = as.character(names(WW[i])),
                         order = j,
                         rsquare = rsquare)
      all_df <- rbind(all_df,t_df)
    }
  }
  return(all_df)
}

# run the model 
runWW <- function(corpus,
                  ws,
                  ti,
                  nw,
                  nth){
  #wc <- windowed_corpus(max_sentences,corpus,ws)
  WW_all <- get_WW_training(corpus = corpus,
                            training_intervals = ti,
                            n_words=nw,
                            ws=ws)
  WW_cosines <- lapply(WW_all,cosine)
  the_results <- get_rsquared(WW_cosines,nth,ws)
  return(the_results)
}

library(foreach)

library(profvis)
profvis({
WW_all <- get_WW_training(corpus=corpus,
                          training_intervals = c(100,1000),
                          n_words = 1000,
                          ws = 8)
})

all_results <- runWW(corpus=corpus,
                  ws=8,
                  ti=c(100,200),
                  nw=1000,
                  nth=nth_similarity)

all_results <- foreach(i=3:8,.combine='rbind') %do% runWW(corpus=corpus,
                                                          ws=i,
                                                          ti=c(100,500,1000,5000),
                                                          nw=1000,
                                                          nth=nth_similarity)

all_results <- all_results %>%
  mutate(order=as.factor(order))

ggplot(all_results, aes(x=training,y=rsquare, group=order, color=order))+
  geom_point()+
  geom_line()+
  ylab("R^2")+
  facet_wrap(~window)
```

## WW with GN transformation

```{r}
GN_transformation <- function(WW){
  GN <- colSums(WW)
  GN_prob <- GN/sum(GN)
  neg_mat<-GN%*%t(GN_prob)*sign(WW)
  GNTran <- WW-neg_mat
  return(GNTran)
}

WW <- matrix(c(0,7,1,4,
  7,0,1,2,
  1,1,0,10,
  4,2,10,0), ncol=4, nrow=4, byrow=T)

GN_transformation(WW)

```

## run model

```{r}
runWW_GN <- function(corpus,
                  ws,
                  ti,
                  nw,
                  nth){
  #wc <- windowed_corpus(max_sentences,corpus,ws)
  WW_all <- get_WW_training(corpus = corpus,
                            training_intervals = ti,
                            n_words=nw,
                            ws=ws)
  WW_all_GN <- lapply(WW_all,GN_transformation)
  WW_cosines <- lapply(WW_all_GN,cosine)
  the_results <- get_rsquared(WW_cosines,nth,ws)
  return(the_results)
}

all_results <- foreach(i=3:8,.combine='rbind') %do% runWW_GN(corpus=corpus,
                                                          ws=i,
                                                          ti=c(100,500,1000,5000),
                                                          nw=100,
                                                          nth=nth_similarity)

all_results <- all_results %>%
  mutate(order=as.factor(order))

ggplot(all_results, aes(x=training,y=rsquare, group=order, color=order))+
  geom_point()+
  geom_line()+
  ylab("R^2")+
  facet_wrap(~window)

```

## WW with DOA

```{r}
popsd <- function(x){
  return(sqrt(sum((mean(x)-x)^2)/length(x)))
}

apply_add <- function(x,y){
  return(x+y)
}

apply_mult <- function(x,y){
  return(x*y)
}

DOA_transformation <- function(WW){
  WW_M <- colMeans(WW)
  WW_sd <- apply(WW,2,popsd)
  WW2 <- apply(WW,2,FUN=function(x){x-WW_M})
  WW2 <- t(apply(WW2,2,FUN=function(x){x/WW_sd}))
  some_ones <- matrix(1,ncol=dim(WW)[1],nrow=dim(WW)[2])
  diag(some_ones)<-0
  WW2 <- WW2*some_ones
  WWrm <- apply(WW2,1,mean)
  WWrsd <- apply(WW2,1,popsd)
  WW4 <- apply(WW2,2,FUN=function(x){x-WWrm} )
  WW4 <- apply(WW4,2,FUN=function(x){x/WWrsd} )
  WW4 <- WW4* some_ones
  return(WW4)
}

DOA_transformation(WW)
```

```{r}
runWW_DOA <- function(corpus,
                  ws,
                  ti,
                  nw,
                  nth){
  #wc <- windowed_corpus(max_sentences,corpus,ws)
  WW_all <- get_WW_training(corpus = corpus,
                            training_intervals = ti,
                            n_words=nw,
                            ws=ws)
  WW_all_DOA <- lapply(WW_all,DOA_transformation)
  WW_cosines <- lapply(WW_all_DOA,cosine)
  the_results <- get_rsquared(WW_cosines,nth,ws)
  return(the_results)
}

all_results <- foreach(i=3:8,.combine='rbind') %do% runWW_DOA(corpus=corpus,
                                                          ws=i,
                                                          ti=c(100,500,1000,5000),
                                                          nw=100,
                                                          nth=nth_similarity)

all_results <- all_results %>%
  mutate(order=as.factor(order))

ggplot(all_results, aes(x=training,y=rsquare, group=order, color=order))+
  geom_point()+
  geom_line()+
  ylab("R^2")+
  facet_wrap(~window)
```
